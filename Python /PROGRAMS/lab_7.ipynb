{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5be50f-fdd6-458b-954e-5cf24e84a396",
   "metadata": {},
   "source": [
    "\n",
    "## Exp.No:12  Estimation of gain in precision due to stratification \n",
    "\n",
    "ALGORITHM:\n",
    "\n",
    "1. START\n",
    "2. Prepare the data\n",
    "3. Build a baseline model using the entire dataset without Stratification\n",
    "4. Stratify the dataset based on the selected stratification variable\n",
    "5. Train a separate model on each stratum of the training set\n",
    "6. Calculate stratified precision\n",
    "7. Estimate gain in precision\n",
    "8. Output the baseline precision and the gain in precision due to Stratification\n",
    "9. STOP \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c970d2-d7e2-4eff-a622-e5461768a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_path = \"train.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df_filtered = df.dropna(subset=['Home Ownership'])\n",
    "\n",
    "stratify_column = 'Home Ownership'\n",
    "\n",
    "train, test = train_test_split(\n",
    "    df_filtered, test_size=0.2, stratify=df_filtered[stratify_column], random_state=42\n",
    ")\n",
    "\n",
    "train_proportions = train[stratify_column].value_counts(normalize=True)\n",
    "test_proportions = test[stratify_column].value_counts(normalize=True)\n",
    "\n",
    "print(\"Training Set Proportions:\")\n",
    "print(train_proportions)\n",
    "print(\"\\nTesting Set Proportions:\")\n",
    "print(test_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456170a-fc3d-485f-a6ac-746cc128a7e8",
   "metadata": {},
   "source": [
    "## Exp.No:13\n",
    "## Problems based on measures of central tendency and measures of dispersion using raw data and grouped data.\n",
    "\n",
    "a.\tTable contains population and murder rates (in units of murders per 100,000 people per year) for different states. Calculate the S.D. and coefficient of variation (C.V.) (raw data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71de9e4a-c3eb-480f-86ee-690d5bcbd0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Murder Rate: 4.62\n",
      "Standard Deviation (S.D.): 1.35\n",
      "Coefficient of Variation (C.V.): 29.21%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given murder rates\n",
    "murder_rates = np.array([5.7, 5.6, 4.7, 5.6, 4.4, 2.8, 2.4, 5.8])\n",
    "\n",
    "# Calculate mean\n",
    "mean_murder_rate = np.mean(murder_rates)\n",
    "\n",
    "# Calculate standard deviation (sample S.D.)\n",
    "std_dev = np.std(murder_rates, ddof=1)  # ddof=1 for sample standard deviation\n",
    "\n",
    "# Calculate Coefficient of Variation (C.V.)\n",
    "cv = (std_dev / mean_murder_rate) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Murder Rate: {mean_murder_rate:.2f}\")\n",
    "print(f\"Standard Deviation (S.D.): {std_dev:.2f}\")\n",
    "print(f\"Coefficient of Variation (C.V.): {cv:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d024340-b8fa-43ec-ae5d-6ad0975255c2",
   "metadata": {},
   "source": [
    "### b.\tCompute the mean, median and variance for the given data(grouped data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848fd66-e778-45eb-bfd9-234084c037dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "class_intervals = [(0,10), (10,20), (20,30), (30,40), (40,50), (50,60), (60,70), (70,80)]\n",
    "frequency = np.array([5, 10, 20, 40, 30, 20, 10, 5])\n",
    "\n",
    "# Compute class midpoints\n",
    "midpoints = np.array([(a + b) / 2 for a, b in class_intervals])\n",
    "\n",
    "# Compute mean\n",
    "mean = np.sum(frequency * midpoints) / np.sum(frequency)\n",
    "\n",
    "# Compute cumulative frequency\n",
    "cumulative_freq = np.cumsum(frequency)\n",
    "N = np.sum(frequency)\n",
    "\n",
    "# Find median class\n",
    "median_class_index = np.where(cumulative_freq >= N/2)[0][0]\n",
    "L = class_intervals[median_class_index][0]\n",
    "CF = cumulative_freq[median_class_index - 1] if median_class_index > 0 else 0\n",
    "f = frequency[median_class_index]\n",
    "h = class_intervals[median_class_index][1] - class_intervals[median_class_index][0]\n",
    "\n",
    "# Compute median\n",
    "median = L + ((N/2 - CF) / f) * h\n",
    "\n",
    "# Compute variance\n",
    "variance = np.sum(frequency * (midpoints - mean) ** 2) / np.sum(frequency)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean: {mean:.2f}\")\n",
    "print(f\"Median: {median:.2f}\")\n",
    "print(f\"Variance: {variance:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
